# .env.example - Add these environment variables for RubyLLM

# === RubyLLM Configuration ===

# OpenAI Configuration (recommended default)
OPENAI_API_KEY=your_openai_api_key_here
# Optional: For organization/project billing
OPENAI_ORGANIZATION_ID=your_openai_org_id
OPENAI_PROJECT_ID=your_openai_project_id

# Anthropic Configuration (alternative provider)
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Google Gemini Configuration (alternative provider)
GEMINI_API_KEY=your_gemini_api_key_here

# Other Providers (optional)
DEEPSEEK_API_KEY=your_deepseek_api_key_here
OPENROUTER_API_KEY=your_openrouter_api_key_here

# Custom OpenAI endpoint (for Azure OpenAI, proxies, etc.)
OPENAI_API_BASE=https://your-azure-endpoint.openai.azure.com

# AWS Bedrock (if using)
AWS_ACCESS_KEY_ID=your_aws_access_key
AWS_SECRET_ACCESS_KEY=your_aws_secret_key
AWS_REGION=us-west-2
AWS_SESSION_TOKEN=your_aws_session_token

# === MCP Configuration (matches your existing config) ===

# LLM Provider for MCP (should match one of the above)
LLM_PROVIDER=openai
LLM_MODEL=gpt-4-turbo-preview

# MCP Feature flags
MCP_ASYNC=false

# Rate limiting
MCP_RATE_LIMIT=100
MCP_RATE_LIMIT_MINUTE=10

# Logging
MCP_LOG_LEVEL=info

# Security
MCP_MAX_MESSAGE_LENGTH=2000
MCP_MAX_CONTEXT_SIZE=10000

# === Optional: HTTP Proxy ===
HTTP_PROXY=http://proxy.company.com:8080

# === Development/Debug Settings ===
RUBYLLM_DEBUG=false

# Complexity Analysis Configuration
# Enable/disable the complexity analysis feature
COMPLEXITY_ANALYSIS_ENABLED=true

# Analysis method: llm_primary, hybrid, keyword_only
COMPLEXITY_ANALYSIS_METHOD=llm_primary

# Enable cultural/linguistic adaptation
CULTURAL_ADAPTATION=true

# Enable user behavior learning (may want to disable in production initially)
USER_LEARNING=false

# Cache duration in seconds (3600 = 1 hour)
COMPLEXITY_CACHE_DURATION=3600

# Request timeout in seconds
COMPLEXITY_ANALYSIS_TIMEOUT=30

# Enable keyword fallback when LLM fails
COMPLEXITY_FALLBACK_ENABLED=true

# Enable debug logging (set per environment)
COMPLEXITY_DEBUG_LOGGING=false

# Enable error reporting to monitoring services
COMPLEXITY_ERROR_REPORTING=false

# Enable metrics collection
COMPLEXITY_METRICS_ENABLED=false

# === Security & Moderation Configuration ===

# Enable/disable OpenAI content moderation
LISTOPIA_USE_MODERATION=true

# Risk threshold for blocking prompt injections (low/medium/high)
# low = 0-2, medium = 3-5, high = 6+
PROMPT_INJECTION_BLOCK_THRESHOLD=high

# Number of violations before auto-archiving a chat
MODERATION_AUTO_ARCHIVE_THRESHOLD=5